{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets for each city\n",
    "df_city1 = pd.read_csv(\"C:/Users/acer/Downloads/Delivery Five Cities Datasets/Delivery Five Cities Datasets/delivery_sh.csv\")\n",
    "df_city2 = pd.read_csv(\"C:/Users/acer/Downloads/Delivery Five Cities Datasets/Delivery Five Cities Datasets/delivery_yt.csv\")\n",
    "df_city3 = pd.read_csv(\"C:/Users/acer/Downloads/Delivery Five Cities Datasets/Delivery Five Cities Datasets/delivery_hz.csv\")\n",
    "df_city4 = pd.read_csv(\"C:/Users/acer/Downloads/Delivery Five Cities Datasets/Delivery Five Cities Datasets/delivery_cq.csv\")\n",
    "df_city5 = pd.read_csv(\"C:/Users/acer/Downloads/Delivery Five Cities Datasets/Delivery Five Cities Datasets/delivery_delivery_jl.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61d921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_city1['city'] = 'City1'\n",
    "df_city2['city'] = 'City2'\n",
    "df_city3['city'] = 'City3'\n",
    "df_city4['city'] = 'City4'\n",
    "df_city5['city'] = 'City5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55490a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df_city1, df_city2, df_city3, df_city4, df_city5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be5e93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4514661 entries, 0 to 4514660\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   order_id           int64         \n",
      " 1   region_id          int64         \n",
      " 2   city               object        \n",
      " 3   courier_id         int64         \n",
      " 4   lng                float64       \n",
      " 5   lat                float64       \n",
      " 6   aoi_id             int64         \n",
      " 7   aoi_type           int64         \n",
      " 8   accept_time        datetime64[ns]\n",
      " 9   accept_gps_time    object        \n",
      " 10  accept_gps_lng     float64       \n",
      " 11  accept_gps_lat     float64       \n",
      " 12  delivery_time      object        \n",
      " 13  delivery_gps_time  object        \n",
      " 14  delivery_gps_lng   float64       \n",
      " 15  delivery_gps_lat   float64       \n",
      " 16  ds                 int64         \n",
      "dtypes: datetime64[ns](1), float64(6), int64(6), object(4)\n",
      "memory usage: 585.6+ MB\n",
      "None\n",
      "city\n",
      "City3    1861600\n",
      "City1    1483864\n",
      "City4     931351\n",
      "City2     206431\n",
      "City5      31415\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.info())\n",
    "print(merged_df['city'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_city_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0061ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078dd97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id  region_id  city   courier_id  lng        lat       aoi_id  aoi_type  accept_time     accept_gps_time  accept_gps_lng  accept_gps_lat  delivery_time   delivery_gps_time  delivery_gps_lng  delivery_gps_lat  ds  \n",
      "0         154        City4  3253        106.26649  29.28891  21674   1         10-23 09:47:00  10-23 09:47:00   106.27495       29.24599        10-23 19:57:00  10-23 19:57:00     106.28845         29.26007          1023    1\n",
      "3009808   19         City3  4466        120.15066  30.33448  3427    1         08-11 08:16:00  08-11 08:16:00   120.13945       30.32906        08-11 17:25:00  08-11 17:25:00     120.15125         30.33431          811     1\n",
      "3009814   3          City3  2791        120.10391  30.27025  52881   1         05-13 08:18:00  05-13 08:18:00   120.09711       30.27140        05-13 08:54:00  05-13 08:54:00     120.10410         30.27065          513     1\n",
      "3009813   105        City4  3689        106.58963  29.74705  1675    14        06-02 15:32:00  06-02 15:32:00   106.63519       29.73245        06-02 19:06:00  06-02 19:06:00     106.58967         29.74719          602     1\n",
      "3009812   0          City3  3175        120.17760  30.26764  13733   1         08-09 08:49:00  08-09 08:49:00   120.18535       30.28075        08-09 09:34:00  08-09 09:34:00     120.17712         30.26779          809     1\n",
      "                                                                                                                                                                                                                              ..\n",
      "1504930   72         City3  468         120.08947  30.29175  23182   1         07-08 16:15:00  07-08 16:15:00   120.09766       30.29169        07-08 17:23:00  07-08 17:23:00     120.08959         30.29155          708     1\n",
      "1504931   110        City4  1259        106.46037  29.59353  43931   1         07-25 14:38:00  07-25 14:38:00   106.49789       29.57342        07-25 17:19:00  07-25 17:19:00     106.46039         29.59378          725     1\n",
      "1504932   23         City3  1587        120.20092  30.32312  40949   1         06-20 09:57:00  06-20 09:57:00   120.18489       30.33908        06-20 13:46:00  06-20 13:46:00     120.20112         30.32318          620     1\n",
      "1504933   45         City1  2411        121.53233  31.04499  17644   1         10-13 13:14:00  10-13 13:14:00   121.52953       31.02338        10-13 15:35:00  10-13 15:35:00     121.53316         31.04534          1013    1\n",
      "4514660   151        City2  2700        121.35143  37.56644  9357    14        10-01 11:02:00  10-01 11:02:00   121.33857       37.54628        10-01 12:39:00  10-01 12:39:00     121.35139         37.56594          1001    1\n",
      "Name: count, Length: 4511284, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd916c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to standardize the format (adjust as needed for your dataset)\n",
    "merged_df['accept_time'] = pd.to_datetime(merged_df['accept_time'], format='%m-%d %H:%M:%S', errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923f1d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                      int64\n",
      "region_id                     int64\n",
      "city                         object\n",
      "courier_id                    int64\n",
      "lng                         float64\n",
      "lat                         float64\n",
      "aoi_id                        int64\n",
      "aoi_type                      int64\n",
      "accept_time          datetime64[ns]\n",
      "accept_gps_time              object\n",
      "accept_gps_lng              float64\n",
      "accept_gps_lat              float64\n",
      "delivery_time                object\n",
      "delivery_gps_time            object\n",
      "delivery_gps_lng            float64\n",
      "delivery_gps_lat            float64\n",
      "ds                            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "814b0dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['accept_gps_lng', 'accept_gps_lat']\n",
      "Missing values after imputation:\n",
      "order_id             0\n",
      "region_id            0\n",
      "city                 0\n",
      "courier_id           0\n",
      "lng                  0\n",
      "lat                  0\n",
      "aoi_id               0\n",
      "aoi_type             0\n",
      "accept_time          0\n",
      "accept_gps_time      0\n",
      "accept_gps_lng       0\n",
      "accept_gps_lat       0\n",
      "delivery_time        0\n",
      "delivery_gps_time    0\n",
      "delivery_gps_lng     0\n",
      "delivery_gps_lat     0\n",
      "ds                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'city' is the column containing city or region information\n",
    "# Replace 'city' with the actual column name representing city or region\n",
    "\n",
    "# Identify columns with missing values\n",
    "missing_columns = merged_df.columns[merged_df.isnull().any()].tolist()\n",
    "print(\"Columns with missing values:\", missing_columns)\n",
    "\n",
    "# Group by city (or region) and compute the mean for each group\n",
    "city_mean = merged_df.groupby('city')[missing_columns].transform('mean')\n",
    "\n",
    "# Impute missing values with the corresponding city mean\n",
    "for column in missing_columns:\n",
    "    merged_df[column] = merged_df[column].fillna(merged_df.groupby('city')[column].transform('mean'))\n",
    "\n",
    "# Verify if there are any missing values left\n",
    "print(\"Missing values after imputation:\")\n",
    "print(merged_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['aoi_type'] = merged_df['aoi_type'].astype('category')\n",
    "print(merged_df['aoi_type'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delivery_duration in minutes\n",
    "merged_df['delivery_duration'] = (pd.to_datetime(merged_df['delivery_time']) - pd.to_datetime(merged_df['accept_time'])).dt.total_seconds() / 60\n",
    "\n",
    "# Detect outliers using Z-score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = zscore(merged_df['delivery_duration'].dropna())  # Drop NA for Z-score calculation\n",
    "outliers = (z_scores < -3) | (z_scores > 3)  # Outlier threshold\n",
    "merged_df = merged_df[~outliers]  # Remove outliers\n",
    "\n",
    "# Or use IQR\n",
    "Q1 = merged_df['delivery_duration'].quantile(0.25)\n",
    "Q3 = merged_df['delivery_duration'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Remove outliers using IQR\n",
    "merged_df = merged_df[\n",
    "    (merged_df['delivery_duration'] >= Q1 - 1.5 * IQR) & \n",
    "    (merged_df['delivery_duration'] <= Q3 + 1.5 * IQR)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0cca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[\n",
    "    (merged_df['lat'].between(-90, 90)) & \n",
    "    (merged_df['lng'].between(-180, 180))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.get_dummies(merged_df, columns=['aoi_type', 'city'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Specify the columns to standardize\n",
    "numerical_features = ['delivery_duration', 'lng', 'lat']  # Add 'distance' if it exists in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "merged_df[numerical_features] = scaler.fit_transform(merged_df[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de212c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean and standard deviation after scaling\n",
    "print(merged_df[numerical_features].mean())\n",
    "print(merged_df[numerical_features].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caee949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path where you want to save the CSV file\n",
    "save_path = \"C:/Users/acer/Documents/cleaned_delivery_data_standardized.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "merged_df.to_csv(save_path, index=False)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "if os.path.exists(save_path):\n",
    "    print(f\"File successfully saved at {save_path}\")\n",
    "else:\n",
    "    print(\"File save failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
